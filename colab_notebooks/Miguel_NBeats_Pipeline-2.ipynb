{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":559,"referenced_widgets":["34b599092693455fb91c3e265566ba4d","44e14ba2457d46bda6293d74330e285a","b5dd9b85283c4b768156d634bb8d9f2e","76df670483fd4b1ead5e338d19ae5200","d3c667cf3cfa4b3cbb96733f696fdf36","b4cf4aa357a04446bfe3f6379fb2c9aa","618a114bb0fd4354a39395a907fbb355","0643498d15c8479989a140a1bf3bd336","f7eb5971fa0b4214977b043a52254893","1739aa501ab64a56be5ea34664c48e7f","2257580dfac3481fb20850810d6a8cce","366f0235175d44f9b42c63802b7e7d8a"]},"id":"Iq5ZkzjlOvlp","outputId":"f8d0a7d6-d33a-44f2-dd07-76c33dade2f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA Available: True\n","Device Name: NVIDIA A100-SXM4-40GB\n","Loading data...\n","Reshaping data (Melt)... this may take a moment.\n","Converting dates...\n","Building TimeSeries objects...\n","Generating covariates...\n","Scaling targets...\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Initializing N-BEATS...\n","Fitting model on full history...\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name            | Type             | Params | Mode \n","-------------------------------------------------------------\n","0 | criterion       | MSELoss          | 0      | train\n","1 | train_criterion | MSELoss          | 0      | train\n","2 | val_criterion   | MSELoss          | 0      | train\n","3 | train_metrics   | MetricCollection | 0      | train\n","4 | val_metrics     | MetricCollection | 0      | train\n","5 | stacks          | ModuleList       | 10.5 M | train\n","-------------------------------------------------------------\n","10.5 M    Trainable params\n","4.6 K     Non-trainable params\n","10.5 M    Total params\n","41.832    Total estimated model params size (MB)\n","396       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34b599092693455fb91c3e265566ba4d","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n","WARNING:darts.models.forecasting.forecasting_model:`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Predicting next 28 days...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"366f0235175d44f9b42c63802b7e7d8a","version_major":2,"version_minor":0},"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Inverse scaling...\n","Formatting submission...\n","Saved submission to submission_nbeats_test.csv\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from datetime import timedelta\n","from darts import TimeSeries\n","from darts.models import NBEATSModel\n","from darts.utils.timeseries_generation import datetime_attribute_timeseries\n","from darts.dataprocessing.transformers import Scaler\n","import torch\n","\n","# ------------------------------------------------------------------------------\n","# 1. SETUP & PARAMETERS\n","# ------------------------------------------------------------------------------\n","START_DATE = pd.Timestamp(\"2011-01-29\")\n","HORIZON = 28\n","\n","# N-BEATS hyperparameters\n","input_chunk_length  = 28\n","output_chunk_length = 14\n","n_epochs            = 10\n","\n","print(f\"CUDA Available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n","\n","# ------------------------------------------------------------------------------\n","# 2. DATA LOADING & MERGING\n","# ------------------------------------------------------------------------------\n","print(\"Loading data...\")\n","# Load Train (d_1 - d_1913)\n","train_df = pd.read_csv(\"sales_train_validation_afcs2025.csv\")\n","\n","# Load Validation (d_1914 - d_1941)\n","valid_df = pd.read_csv(\"sales_test_validation_afcs2025.csv\")\n","\n","# Extract 'd_' columns and ensure they are sorted numerically\n","def get_d_cols(df):\n","    cols = [c for c in df.columns if c.startswith(\"d_\")]\n","    return sorted(cols, key=lambda x: int(x.split('_')[1]))\n","\n","train_cols = get_d_cols(train_df)\n","valid_cols = get_d_cols(valid_df)\n","\n","# Align Validation IDs to Training IDs (just in case)\n","ids = train_df['id'].values\n","valid_df_aligned = valid_df.set_index('id').reindex(ids).reset_index()\n","\n","# Merge the columns to create one wide DataFrame (d_1 ... d_1941)\n","# We take static cols from train_df and append the validation d_cols\n","static_cols = [c for c in train_df.columns if c not in train_cols]\n","sales_wide = pd.concat([train_df[static_cols + train_cols], valid_df_aligned[valid_cols]], axis=1)\n","\n","print(\"Reshaping data (Melt)... this may take a moment.\")\n","# All d_ columns in the new combined dataframe\n","all_d_cols = train_cols + valid_cols\n","\n","sales_long = sales_wide.melt(\n","    id_vars=static_cols,\n","    value_vars=all_d_cols,\n","    var_name='d',\n","    value_name='y'\n",")\n","\n","# Convert 'd_xx' -> datetime\n","print(\"Converting dates...\")\n","sales_long['day_num'] = sales_long['d'].str.slice(2).astype(int)\n","sales_long['ds'] = START_DATE + pd.to_timedelta(sales_long['day_num'] - 1, unit='D')\n","\n","# Final cleanup for Darts\n","sales_df = (\n","    sales_long[['id', 'ds', 'y']]\n","    .rename(columns={'id': 'unique_id'})\n","    .sort_values(by=['unique_id', 'ds'])\n","    .reset_index(drop=True)\n",")\n","\n","# Ensure proper dtypes\n","sales_df[\"unique_id\"] = sales_df[\"unique_id\"].astype(str)\n","sales_df[\"y\"] = pd.to_numeric(sales_df[\"y\"], errors=\"coerce\")\n","\n","# ------------------------------------------------------------------------------\n","# 3. DARTS TIMESERIES CREATION\n","# ------------------------------------------------------------------------------\n","print(\"Building TimeSeries objects...\")\n","series_list = TimeSeries.from_group_dataframe(\n","    sales_df,\n","    group_cols=\"unique_id\",\n","    time_col=\"ds\",\n","    value_cols=\"y\",\n","    fill_missing_dates=True,\n","    freq='D'\n",")\n","\n","# ------------------------------------------------------------------------------\n","# 4. COVARIATES GENERATION\n","# ------------------------------------------------------------------------------\n","print(\"Generating covariates...\")\n","\n","# We need covariates for History + Forecast Horizon\n","min_date = sales_df['ds'].min()\n","max_date = sales_df['ds'].max()\n","forecast_end_date = max_date + timedelta(days=HORIZON)\n","\n","# Create global timeline\n","full_time_index = pd.date_range(start=min_date, end=forecast_end_date, freq='D')\n","\n","# Dummy series for attributes\n","global_cov_ts = TimeSeries.from_times_and_values(\n","    times=full_time_index,\n","    values=np.zeros(len(full_time_index))\n",")\n","\n","# Generate Calendar Features\n","month_cov = datetime_attribute_timeseries(global_cov_ts, attribute=\"month\", one_hot=True)\n","day_cov = datetime_attribute_timeseries(global_cov_ts, attribute=\"dayofweek\", one_hot=True)\n","global_covariates = month_cov.stack(day_cov)\n","\n","# Replicate for each series (Darts expects list of covariates matching list of series)\n","covariates_list = [global_covariates] * len(series_list)\n","\n","# Scale targets\n","print(\"Scaling targets...\")\n","scaler = Scaler()\n","series_list_scaled = scaler.fit_transform(series_list)\n","\n","# ------------------------------------------------------------------------------\n","# 5. MODEL TRAINING\n","# ------------------------------------------------------------------------------\n","print(\"Initializing N-BEATS...\")\n","model = NBEATSModel(\n","    input_chunk_length=int(input_chunk_length),\n","    output_chunk_length=int(output_chunk_length),\n","    n_epochs=int(n_epochs),\n","    random_state=42,\n","    model_name=\"nbeats-full-history\",\n","    force_reset=True,\n","    save_checkpoints=False,\n","    pl_trainer_kwargs={\n","        \"accelerator\": \"gpu\",\n","        \"devices\": 1\n","    },\n","    batch_size=1024\n",")\n","\n","print(\"Fitting model on full history...\")\n","model.fit(\n","    series=series_list_scaled,\n","    past_covariates=covariates_list,\n","    verbose=True\n",")\n","\n","# ------------------------------------------------------------------------------\n","# 6. FORECASTING & EXPORT\n","# ------------------------------------------------------------------------------\n","print(f\"Predicting next {HORIZON} days...\")\n","preds_scaled = model.predict(\n","    n=HORIZON,\n","    series=series_list_scaled,\n","    past_covariates=covariates_list\n",")\n","\n","print(\"Inverse scaling...\")\n","preds = scaler.inverse_transform(preds_scaled)\n","\n","print(\"Formatting submission...\")\n","# Convert Darts TimeSeries objects back to DataFrame format\n","# preds is a list of TimeSeries. We need to stack them.\n","pred_rows = []\n","for i, ts in enumerate(preds):\n","    # Extract ID from the static info or original list order\n","    s_id = series_list[i].static_covariates_values()[0,0] if series_list[i].static_covariates is not None else ids[i]\n","\n","    # Get values (Shape: Horizon x 1)\n","    vals = ts.values().flatten()\n","\n","    # Create row: [id, F1, F2, ... F28]\n","    row = [s_id] + list(vals)\n","    pred_rows.append(row)\n","\n","# Define columns\n","f_cols = [f\"F{x}\" for x in range(1, HORIZON + 1)]\n","submission_df = pd.DataFrame(pred_rows, columns=['id'] + f_cols)\n","\n","# Save\n","submission_file = \"submission_nbeats_test.csv\"\n","submission_df.to_csv(submission_file, index=False)\n","print(f\"Saved submission to {submission_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":30,"status":"error","timestamp":1766501216010,"user":{"displayName":"Malak Khan","userId":"15350697901096315039"},"user_tz":-60},"id":"Q3cfkdHdUtKu","outputId":"8432282c-04c3-45cb-e9f2-499ee225f592"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:darts.models.forecasting.forecasting_model:`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"]},{"name":"stdout","output_type":"stream","text":["Predicting...\n"]},{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'set_predict_parameters'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1223402407.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m forecasts_scaled = model.predict(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhorizon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mseries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseries_list_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/darts/utils/torch.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfork_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TORCH_SEED_VALUE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/darts/models/forecasting/torch_forecasting_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, n, series, past_covariates, future_covariates, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters, show_warnings, random_state)\u001b[0m\n\u001b[1;32m   1696\u001b[0m         )\n\u001b[1;32m   1697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m         predictions = self.predict_from_dataset(\n\u001b[0m\u001b[1;32m   1699\u001b[0m             \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/darts/utils/torch.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfork_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TORCH_SEED_VALUE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/darts/models/forecasting/torch_forecasting_model.py\u001b[0m in \u001b[0;36mpredict_from_dataset\u001b[0;34m(self, n, dataset, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters, random_state, values_only)\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0;31m# set prediction parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m         self.model.set_predict_parameters(\n\u001b[0m\u001b[1;32m   1829\u001b[0m             \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'set_predict_parameters'"]}],"source":["\n","# ------------------------------------------------------------------------------\n","# 6. FORECASTING & SUBMISSION GENERATION\n","# ------------------------------------------------------------------------------\n","print(\"Predicting...\")\n","forecasts_scaled = model.predict(\n","    n=horizon,\n","    series=series_list_scaled,\n","    past_covariates=covariates_list,\n","    verbose=True\n",")\n","\n","# Inverse scale\n","forecasts = scaler.inverse_transform(forecasts_scaled)\n","\n","print(\"Formatting submission...\")\n","# Convert list of TimeSeries back to a DataFrame\n","fcst_dfs = []\n","for ts, fc in zip(series_list, forecasts):\n","    # Extract the ID from the static covariates or components\n","    # Note: from_group_dataframe puts the group ID in static_covariates\n","    s_id = ts.static_covariates.iloc[0,0] if ts.static_covariates is not None else \"unknown\"\n","\n","    # Create DataFrame: ds, yhat\n","    df_fc = fc.to_dataframe().reset_index()\n","    # Column 0 is time, Column 1 is the prediction\n","    df_fc.columns = ['ds', 'yhat']\n","    df_fc['id'] = s_id\n","    fcst_dfs.append(df_fc)\n","\n","forecast_long = pd.concat(fcst_dfs, ignore_index=True)\n","\n","# Pivot to Wide Format (id, F1...F28)\n","# We need to rank the dates to get F1, F2, etc.\n","forecast_long['F_col'] = forecast_long.groupby('id')['ds'].rank(method='first').astype(int)\n","forecast_long['F_col'] = \"F\" + forecast_long['F_col'].astype(str)\n","\n","submission_df = forecast_long.pivot(index='id', columns='F_col', values='yhat').reset_index()\n","\n","# Ensure we match the sample submission order and columns\n","sample_sub = pd.read_csv(\"sample_submission_afcs2025.csv\")\n","# Right join or reindex to ensure we have all IDs in correct order\n","final_submission = sample_sub[['id']].merge(submission_df, on='id', how='left')\n","\n","# Fill NaNs with 0 if any\n","final_submission = final_submission.fillna(0)\n","\n","# Save\n","output_path = \"submission_nbeats.csv\"\n","final_submission.to_csv(output_path, index=False)\n","print(f\"Submission saved to {output_path}\")\n","print(final_submission.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1766498435485,"user":{"displayName":"Malak Khan","userId":"15350697901096315039"},"user_tz":-60},"id":"NblrshpgS6NA","outputId":"143a3860-6e5d-4f2f-8d36-e63d6ed390d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation RMSE: 3.17983\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# 1. Load the Data\n","# Ground Truth (Validation set)\n","gt_df = pd.read_csv(\"sales_test_validation_afcs2025.csv\")\n","\n","# Predictions (Your generated submission file)\n","pred_df = pd.read_csv(\"submission_nbeats.csv\")\n","\n","# 2. Align DataFrames by ID\n","# We verify that we are comparing the same items in the same order.\n","# Sort both by 'id' to ensure row-to-row correspondence.\n","gt_df = gt_df.sort_values(\"id\").reset_index(drop=True)\n","pred_df = pred_df.sort_values(\"id\").reset_index(drop=True)\n","\n","# Verify IDs match\n","if not gt_df[\"id\"].equals(pred_df[\"id\"]):\n","    print(\"Warning: IDs do not match perfectly. Performing an inner join alignment...\")\n","    # Rename columns to avoid collisions if necessary, or just merge on ID\n","    # Here we simply filter to common IDs\n","    common_ids = pd.Series(list(set(gt_df['id']) & set(pred_df['id'])))\n","    gt_df = gt_df[gt_df['id'].isin(common_ids)].sort_values('id').reset_index(drop=True)\n","    pred_df = pred_df[pred_df['id'].isin(common_ids)].sort_values('id').reset_index(drop=True)\n","\n","# 3. Extract Values\n","# Ground Truth columns: d_1914, d_1915, ..., d_1941 (excluding 'id')\n","y_true = gt_df.drop(columns=[\"id\"]).values\n","\n","# Prediction columns: F1, F2, ..., F28 (excluding 'id')\n","y_pred = pred_df.drop(columns=[\"id\"]).values\n","\n","# 4. Calculate RMSE\n","# Flatten arrays to compute global RMSE across all series and time steps\n","rmse = sqrt(mean_squared_error(y_true, y_pred))\n","\n","print(f\"Validation RMSE: {rmse:.5f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuXs_oZLsXG6","colab":{"base_uri":"https://localhost:8080/","height":664,"referenced_widgets":["7feb2938dd9c438fb2c4f7330e97dcf9","92c42e5338d24751abe3a6b6d4219372","5806bcfe327f4630872d0a8fdd3b1554","3d08acf5d7404840b7328f0592a9ca5e","671fa8fe643943e7847b61ef675bd779","db5406af673749b1ad40cd7e81ea3270","5e97e57c56814ef68f7164f274c3adfa","81edb207682947cc962cea50ffc034fe","29a7b22c466e4ace9e231426942c8a16","5255d39c02f948589b05127e0b95b1e3","f2e8ff2cc4f94042a27cea0320b0537c"]},"outputId":"aed7e5a7-47dd-4926-e158-163b8638e08a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:darts.models:The StatsForecast module could not be imported. To enable support for the AutoARIMA, AutoETS and Croston models, please consider installing it.\n"]},{"output_type":"stream","name":"stdout","text":["CUDA Available: True\n","Device Name: NVIDIA A100-SXM4-80GB\n","Loading data...\n","Training cols: 1913, Validation cols: 28\n","Reshaping training data (Melt)... this may take a moment.\n","Converting dates...\n","Building TimeSeries objects...\n","Generating covariates...\n","Scaling targets...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n","  return _C._get_float32_matmul_precision()\n","INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":["Initializing N-BEATS...\n","Fitting model on combined (Train + Validation) history...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name            | Type             | Params | Mode \n","-------------------------------------------------------------\n","0 | criterion       | MSELoss          | 0      | train\n","1 | train_criterion | MSELoss          | 0      | train\n","2 | val_criterion   | MSELoss          | 0      | train\n","3 | train_metrics   | MetricCollection | 0      | train\n","4 | val_metrics     | MetricCollection | 0      | train\n","5 | stacks          | ModuleList       | 10.5 M | train\n","-------------------------------------------------------------\n","10.5 M    Trainable params\n","4.6 K     Non-trainable params\n","10.5 M    Total params\n","41.832    Total estimated model params size (MB)\n","396       Modules in train mode\n","0         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7feb2938dd9c438fb2c4f7330e97dcf9"}},"metadata":{}}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from datetime import timedelta\n","from darts import TimeSeries\n","from darts.models import NBEATSModel\n","from darts.utils.timeseries_generation import datetime_attribute_timeseries\n","from darts.dataprocessing.transformers import Scaler\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","import torch\n","\n","# ------------------------------------------------------------------------------\n","# 1. SETUP & PARAMETERS\n","# ------------------------------------------------------------------------------\n","START_DATE = pd.Timestamp(\"2011-01-29\")\n","HORIZON = 28\n","\n","# N-BEATS hyperparameters\n","input_chunk_length  = 28\n","output_chunk_length = 14\n","n_epochs            = 10\n","\n","print(f\"CUDA Available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n","\n","# ------------------------------------------------------------------------------\n","# 2. DATA LOADING & MERGING (TRAIN + VALIDATION)\n","# ------------------------------------------------------------------------------\n","print(\"Loading data...\")\n","# 1. Load Train (d_1 - d_1913)\n","train_df = pd.read_csv(\"sales_train_validation_afcs2025.csv\")\n","\n","# 2. Load Validation (d_1914 - d_1941)\n","valid_df = pd.read_csv(\"sales_test_validation_afcs2025.csv\")\n","\n","# 3. Load Evaluation (Ground Truth for d_1942 - d_1969)\n","eval_df = pd.read_csv(\"sales_test_evaluation_afcs_2025.csv\")\n","\n","# Helper to sort d_ cols\n","def get_d_cols(df):\n","    cols = [c for c in df.columns if c.startswith(\"d_\")]\n","    return sorted(cols, key=lambda x: int(x.split('_')[1]))\n","\n","train_cols = get_d_cols(train_df)\n","valid_cols = get_d_cols(valid_df)\n","\n","print(f\"Training cols: {len(train_cols)}, Validation cols: {len(valid_cols)}\")\n","\n","# Align IDs (Ensure rows match)\n","ids = train_df['id'].values\n","valid_df = valid_df.set_index('id').reindex(ids).reset_index()\n","eval_df = eval_df.set_index('id').reindex(ids).reset_index()\n","\n","# Combine Train + Validation into one DataFrame for training\n","# We take static cols from train_df and append the validation d_cols\n","static_cols = [c for c in train_df.columns if c not in train_cols]\n","# Ensure we only have static cols + d_cols (filtering out any accidental extras)\n","full_train_wide = pd.concat([train_df[static_cols + train_cols], valid_df[valid_cols]], axis=1)\n","\n","print(\"Reshaping training data (Melt)... this may take a moment.\")\n","all_train_cols = train_cols + valid_cols # d_1 to d_1941\n","\n","sales_long = full_train_wide.melt(\n","    id_vars=static_cols,\n","    value_vars=all_train_cols,\n","    var_name='d',\n","    value_name='y'\n",")\n","\n","# Convert 'd_xx' -> datetime\n","print(\"Converting dates...\")\n","sales_long['day_num'] = sales_long['d'].str.slice(2).astype(int)\n","sales_long['ds'] = START_DATE + pd.to_timedelta(sales_long['day_num'] - 1, unit='D')\n","\n","# Final cleanup for Darts\n","sales_df = (\n","    sales_long[['id', 'ds', 'y']]\n","    .rename(columns={'id': 'unique_id'})\n","    .sort_values(by=['unique_id', 'ds'])\n","    .reset_index(drop=True)\n",")\n","\n","sales_df[\"unique_id\"] = sales_df[\"unique_id\"].astype(str)\n","sales_df[\"y\"] = pd.to_numeric(sales_df[\"y\"], errors=\"coerce\").fillna(0)\n","\n","# ------------------------------------------------------------------------------\n","# 3. DARTS TIMESERIES CREATION\n","# ------------------------------------------------------------------------------\n","print(\"Building TimeSeries objects...\")\n","series_list = TimeSeries.from_group_dataframe(\n","    sales_df,\n","    group_cols=\"unique_id\",\n","    time_col=\"ds\",\n","    value_cols=\"y\",\n","    fill_missing_dates=True,\n","    freq='D'\n",")\n","\n","# ------------------------------------------------------------------------------\n","# 4. COVARIATES GENERATION\n","# ------------------------------------------------------------------------------\n","print(\"Generating covariates...\")\n","\n","# We need covariates for History (d_1...d_1941) + Forecast Horizon (d_1942...d_1969)\n","min_date = sales_df['ds'].min()\n","max_date = sales_df['ds'].max()\n","forecast_end_date = max_date + timedelta(days=HORIZON)\n","\n","full_time_index = pd.date_range(start=min_date, end=forecast_end_date, freq='D')\n","\n","global_cov_ts = TimeSeries.from_times_and_values(\n","    times=full_time_index,\n","    values=np.zeros(len(full_time_index))\n",")\n","\n","month_cov = datetime_attribute_timeseries(global_cov_ts, attribute=\"month\", one_hot=True)\n","day_cov = datetime_attribute_timeseries(global_cov_ts, attribute=\"dayofweek\", one_hot=True)\n","global_covariates = month_cov.stack(day_cov)\n","\n","covariates_list = [global_covariates] * len(series_list)\n","\n","# Scale targets\n","print(\"Scaling targets...\")\n","scaler = Scaler()\n","series_list_scaled = scaler.fit_transform(series_list)\n","\n","# ------------------------------------------------------------------------------\n","# 5. MODEL TRAINING\n","# ------------------------------------------------------------------------------\n","print(\"Initializing N-BEATS...\")\n","model = NBEATSModel(\n","    input_chunk_length=int(input_chunk_length),\n","    output_chunk_length=int(output_chunk_length),\n","    n_epochs=int(n_epochs),\n","    random_state=42,\n","    model_name=\"nbeats-full-history\",\n","    force_reset=True,\n","    save_checkpoints=False,\n","    pl_trainer_kwargs={\n","        \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n","        \"devices\": 1\n","    },\n","    batch_size=1024\n",")\n","\n","print(\"Fitting model on combined (Train + Validation) history...\")\n","model.fit(\n","    series=series_list_scaled,\n","    past_covariates=covariates_list,\n","    verbose=True\n",")\n","\n","# ------------------------------------------------------------------------------\n","# 6. FORECASTING\n","# ------------------------------------------------------------------------------\n","print(f\"Predicting next {HORIZON} days (d_1942 - d_1969)...\")\n","preds_scaled = model.predict(\n","    n=HORIZON,\n","    series=series_list_scaled,\n","    past_covariates=covariates_list\n",")\n","\n","print(\"Inverse scaling predictions...\")\n","preds = scaler.inverse_transform(preds_scaled)\n","\n","# ------------------------------------------------------------------------------\n","# 7. EVALUATION (RMSE vs TEST EVALUATION SET)\n","# ------------------------------------------------------------------------------\n","print(\"Calculating RMSE against Ground Truth (sales_test_evaluation_afcs_2025.csv)...\")\n","\n","# 1. Prepare Ground Truth Array\n","# Select only the relevant d_columns (d_1942 ... d_1969)\n","eval_cols = get_d_cols(eval_df)\n","# Ensure we sort the ground truth rows by ID to match the predictions order\n","# (We already aligned eval_df IDs in Step 2, but good to be safe)\n","y_true = eval_df[eval_cols].values\n","\n","# 2. Prepare Prediction Array\n","# preds is a list of TimeSeries. We need to stack them into a matrix (N_series x Horizon)\n","pred_vals = []\n","for i, ts in enumerate(preds):\n","    pred_vals.append(ts.values().flatten())\n","\n","y_pred = np.array(pred_vals)\n","\n","# 3. Compute RMSE\n","# We compute one global RMSE (all series, all days)\n","mse = mean_squared_error(y_true, y_pred)\n","rmse = sqrt(mse)\n","\n","print(\"=\"*40)\n","print(f\"GLOBAL RMSE: {rmse:.5f}\")\n","print(\"=\"*40)\n","\n","# Optional: Save predictions to CSV for inspection\n","print(\"Saving predictions to 'submission_nbeats_eval.csv'...\")\n","f_cols = [f\"F{x}\" for x in range(1, HORIZON + 1)]\n","submission_df = pd.DataFrame(y_pred, columns=f_cols)\n","submission_df.insert(0, 'id', ids) # Use the aligned IDs\n","submission_df.to_csv(\"submission_nbeats_eval.csv\", index=False)\n","print(\"Done.\")"]},{"cell_type":"code","source":[],"metadata":{"id":"YhJEn1f0tBF6"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNr0+c1k5LCgMvnBbRRvfLO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0643498d15c8479989a140a1bf3bd336":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1739aa501ab64a56be5ea34664c48e7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2257580dfac3481fb20850810d6a8cce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34b599092693455fb91c3e265566ba4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_44e14ba2457d46bda6293d74330e285a","IPY_MODEL_b5dd9b85283c4b768156d634bb8d9f2e","IPY_MODEL_76df670483fd4b1ead5e338d19ae5200"],"layout":"IPY_MODEL_d3c667cf3cfa4b3cbb96733f696fdf36"}},"44e14ba2457d46bda6293d74330e285a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4cf4aa357a04446bfe3f6379fb2c9aa","placeholder":"​","style":"IPY_MODEL_618a114bb0fd4354a39395a907fbb355","value":"Epoch 1:  80%"}},"618a114bb0fd4354a39395a907fbb355":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76df670483fd4b1ead5e338d19ae5200":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1739aa501ab64a56be5ea34664c48e7f","placeholder":"​","style":"IPY_MODEL_2257580dfac3481fb20850810d6a8cce","value":" 1220/1528 [01:37&lt;00:24, 12.50it/s, train_loss=0.0115]"}},"b4cf4aa357a04446bfe3f6379fb2c9aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5dd9b85283c4b768156d634bb8d9f2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0643498d15c8479989a140a1bf3bd336","max":1528,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7eb5971fa0b4214977b043a52254893","value":1220}},"d3c667cf3cfa4b3cbb96733f696fdf36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"f7eb5971fa0b4214977b043a52254893":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7feb2938dd9c438fb2c4f7330e97dcf9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92c42e5338d24751abe3a6b6d4219372","IPY_MODEL_5806bcfe327f4630872d0a8fdd3b1554","IPY_MODEL_3d08acf5d7404840b7328f0592a9ca5e"],"layout":"IPY_MODEL_671fa8fe643943e7847b61ef675bd779"}},"92c42e5338d24751abe3a6b6d4219372":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db5406af673749b1ad40cd7e81ea3270","placeholder":"​","style":"IPY_MODEL_5e97e57c56814ef68f7164f274c3adfa","value":"Epoch 2:  65%"}},"5806bcfe327f4630872d0a8fdd3b1554":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_81edb207682947cc962cea50ffc034fe","max":1528,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29a7b22c466e4ace9e231426942c8a16","value":1000}},"3d08acf5d7404840b7328f0592a9ca5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5255d39c02f948589b05127e0b95b1e3","placeholder":"​","style":"IPY_MODEL_f2e8ff2cc4f94042a27cea0320b0537c","value":" 1000/1528 [01:20&lt;00:42, 12.48it/s, train_loss=0.0105]"}},"671fa8fe643943e7847b61ef675bd779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"db5406af673749b1ad40cd7e81ea3270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e97e57c56814ef68f7164f274c3adfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81edb207682947cc962cea50ffc034fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29a7b22c466e4ace9e231426942c8a16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5255d39c02f948589b05127e0b95b1e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2e8ff2cc4f94042a27cea0320b0537c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}