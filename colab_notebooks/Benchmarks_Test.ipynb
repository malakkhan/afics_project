{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNSFuiuzirkgPd/pMSSQfc7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iFgCRWhokMi1"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# -------------------------------------------------------------------------\n","# 1. LOAD DATA & CREATE FULL HISTORY\n","# -------------------------------------------------------------------------\n","# Load Train (d_1 - d_1913)\n","train_df = pd.read_csv(\"sales_train_validation_afcs2025.csv\")\n","\n","# Load Validation (d_1914 - d_1941) - This is now part of history\n","valid_df = pd.read_csv(\"sales_test_validation_afcs2025.csv\")\n","\n","# Load Test (d_1942 - d_1969) - This is our NEW Ground Truth\n","test_df = pd.read_csv(\"sales_test_evaluation_afcs_2025.csv\")\n","\n","# Extract 'd_' columns and ensure they are sorted numerically\n","def get_d_cols(df):\n","    cols = [c for c in df.columns if c.startswith(\"d_\")]\n","    return sorted(cols, key=lambda x: int(x.split('_')[1]))\n","\n","train_cols = get_d_cols(train_df)\n","valid_cols = get_d_cols(valid_df)\n","test_cols = get_d_cols(test_df)\n","\n","# Align everything to the training IDs\n","ids = train_df['id'].values\n","\n","# Helper to align and extract data arrays\n","def get_data_aligned(source_df, target_ids, cols):\n","    # Set index to ID, reindex to match target_ids, and extract values\n","    return source_df.set_index('id').reindex(target_ids)[cols].values\n","\n","# 1. Create History Data: Train + Validation (Concatenate along time axis)\n","# Shape: (n_series, 1913 + 28) = (n_series, 1941)\n","data_train = train_df.set_index('id').reindex(ids)[train_cols].values\n","data_valid = get_data_aligned(valid_df, ids, valid_cols)\n","history_data = np.concatenate([data_train, data_valid], axis=1)\n","\n","# 2. Get Ground Truth for Test Period\n","y_true = get_data_aligned(test_df, ids, test_cols)\n","\n","H = 28  # Horizon\n","\n","# -------------------------------------------------------------------------\n","# 2. MODELS (Applied to history_data)\n","# -------------------------------------------------------------------------\n","\n","# --- A. SNAIVE MODEL (Yearly: Lag 364) ---\n","SEASON_LAG_YEAR = 364\n","# We take the slice from [End - 364] to [End - 364 + 28]\n","snaive_yearly_preds = history_data[:, -SEASON_LAG_YEAR : -SEASON_LAG_YEAR + H]\n","\n","# --- B. SNAIVE MODEL (Weekly: Lag 7) ---\n","SEASON_LAG_WEEK = 7\n","# Take last 7 days of history and tile 4 times (7*4=28)\n","last_week_pattern = history_data[:, -SEASON_LAG_WEEK:]\n","snaive_weekly_preds = np.tile(last_week_pattern, (1, 4))\n","\n","# --- C. SNAIVE MODEL (Monthly: Lag 28) ---\n","SEASON_LAG_MONTH = 28\n","# Take exactly the last 28 days of history\n","snaive_monthly_preds = history_data[:, -SEASON_LAG_MONTH : ]\n","\n","# --- D. NAIVE MODEL ---\n","# Last observed value (d_1941) repeated\n","last_value = history_data[:, -1:]\n","naive_preds = np.tile(last_value, (1, H))\n","\n","# --- E. GLOBAL MEAN MODEL ---\n","# Mean of entire history (d_1 ... d_1941)\n","series_mean = np.mean(history_data, axis=1, keepdims=True)\n","mean_preds = np.tile(series_mean, (1, H))\n","\n","# --- F. RW WITH DRIFT ---\n","# Slope from d_1 to d_1941\n","n_timesteps = history_data.shape[1]\n","y_last = history_data[:, -1:]\n","y_first = history_data[:, :1] # d_1\n","\n","slope = (y_last - y_first) / (n_timesteps - 1)\n","horizon_indices = np.arange(1, H + 1).reshape(1, H)\n","drift_preds = y_last + (slope * horizon_indices)\n","\n","# --- G. CROSTON MODEL ---\n","def apply_croston(x, alpha=0.1, h=28):\n","    nz_idx = np.nonzero(x)[0]\n","    if len(nz_idx) == 0:\n","        return np.zeros(h)\n","\n","    # Intervals & Demand\n","    intervals = np.diff(np.r_[-1, nz_idx])\n","    q = x[nz_idx]\n","\n","    # Initialization\n","    z = q[0]\n","    p = intervals[0]\n","\n","    # Recursion\n","    for i in range(1, len(nz_idx)):\n","        z = alpha * q[i] + (1 - alpha) * z\n","        p = alpha * intervals[i] + (1 - alpha) * p\n","\n","    forecast_val = z / p\n","    return np.full(h, forecast_val)\n","\n","croston_preds = np.array([apply_croston(row, h=H) for row in history_data])\n","\n","# -------------------------------------------------------------------------\n","# 3. CALCULATE RMSE\n","# -------------------------------------------------------------------------\n","print(f\"{'Model':<20} | RMSE\")\n","print(\"-\" * 30)\n","\n","models = {\n","    \"SNaive (Yearly)\": snaive_yearly_preds,\n","    \"SNaive (Weekly)\": snaive_weekly_preds,\n","    \"SNaive (Monthly)\": snaive_monthly_preds,\n","    \"Naive\": naive_preds,\n","    \"Mean\": mean_preds,\n","    \"Drift\": drift_preds,\n","    \"Croston\": croston_preds\n","}\n","\n","for name, preds in models.items():\n","    rmse = sqrt(mean_squared_error(y_true, preds))\n","    print(f\"{name:<20} | {rmse:.4f}\")\n","\n","# -------------------------------------------------------------------------\n","# 4. SAVE SUBMISSIONS (Optional)\n","# -------------------------------------------------------------------------\n","f_cols = [f\"F{i}\" for i in range(1, 29)]\n","# Example: Saving Yearly SNaive\n","sub = pd.DataFrame(snaive_yearly_preds, columns=f_cols)\n","sub.insert(0, 'id', ids)\n","sub.to_csv(\"submission_test_snaive_yearly.csv\", index=False)"]}]}