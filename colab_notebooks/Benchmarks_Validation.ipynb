{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyMbznf4S6uk/nZSnWIaGNy2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UWF9ebXcWe57"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# -------------------------------------------------------------------------\n","# 1. LOAD DATA\n","# -------------------------------------------------------------------------\n","# Train: 1913 days (d_1 ... d_1913)\n","train_df = pd.read_csv(\"sales_train_validation_afcs2025.csv\")\n","\n","# Validation (Ground Truth): 28 days (d_1914 ... d_1941)\n","val_df = pd.read_csv(\"sales_test_validation_afcs2025.csv\")\n","\n","# Sort/Ensure alignment of d_cols\n","d_cols = [c for c in train_df.columns if c.startswith(\"d_\")]\n","d_cols = sorted(d_cols, key=lambda x: int(x.split('_')[1]))\n","\n","train_data = train_df[d_cols].values\n","ids = train_df['id'].values\n","H = 28 # Horizon\n","\n","# -------------------------------------------------------------------------\n","# 2. SNAIVE MODEL (Lag 364)\n","# -------------------------------------------------------------------------\n","# \"lag('year')\" corresponds to 52 weeks * 7 days = 364 days.\n","# This preserves the Day-of-Week alignment (e.g., Monday vs Monday).\n","SEASON_LAG = 364\n","\n","# We take the slice of history from [T - 364] to [T - 364 + 28]\n","# to predict [T + 1] to [T + 28].\n","snaive_preds = train_data[:, -SEASON_LAG : -SEASON_LAG + H]\n","\n","import numpy as np\n","\n","# -------------------------------------------------------------------------\n","# SNAIVE MODEL (Weekly Seasonality)\n","# -------------------------------------------------------------------------\n","# \"lag('week')\" corresponds to 7 days.\n","SEASON_LAG = 7\n","\n","# Since the Horizon (28) > Season (7), we cannot just slice one instance.\n","# We take the last 7 days of history and repeat them to fill 28 days.\n","# Logic: Take [-7:] and tile it 4 times (since 7 * 4 = 28).\n","last_week_pattern = train_data[:, -SEASON_LAG:]\n","snaive_weekly_preds = np.tile(last_week_pattern, (1, 4)) # Result shape: [Batch, 28]\n","\n","# -------------------------------------------------------------------------\n","# SNAIVE MODEL (Monthly Seasonality)\n","# -------------------------------------------------------------------------\n","# \"lag('month')\" is approx 30 days, but 28 days (4 weeks) is preferred\n","# to maintain Day-of-Week alignment (e.g. Monday to Monday).\n","SEASON_LAG = 28\n","\n","# We take the slice of history from [T - 28] to [T]\n","# to predict [T + 1] to [T + 28].\n","# Note: Since SEASON_LAG == H, this slices exactly the last 28 days.\n","snaive_monthly_preds = train_data[:, -SEASON_LAG : ]\n","\n","# -------------------------------------------------------------------------\n","# 3. CROSTON MODEL\n","# -------------------------------------------------------------------------\n","def apply_croston(x, alpha=0.1, h=28):\n","    \"\"\"\n","    Simple Croston's Method implementation.\n","    Separates demand into size (q) and interval (a).\n","    \"\"\"\n","    # Find non-zero indices\n","    nz_idx = np.nonzero(x)[0]\n","\n","    if len(nz_idx) == 0:\n","        return np.zeros(h)\n","\n","    # 1. Intervals (difference between non-zero indices)\n","    # We prepend -1 so the first interval is the time to the first sale\n","    intervals = np.diff(np.r_[-1, nz_idx])\n","\n","    # 2. Demand Sizes\n","    q = x[nz_idx]\n","\n","    # 3. Recursive Smoothing\n","    # Initialize with the first observed values\n","    z = q[0]     # Smoothed Size\n","    p = intervals[0] # Smoothed Interval\n","\n","    # Update loop starting from 2nd non-zero observation\n","    for i in range(1, len(nz_idx)):\n","        z = alpha * q[i] + (1 - alpha) * z\n","        p = alpha * intervals[i] + (1 - alpha) * p\n","\n","    # Final Forecast = Smoothed Size / Smoothed Interval\n","    forecast_val = z / p\n","    return np.full(h, forecast_val)\n","\n","# Apply to all rows\n","croston_preds = np.array([apply_croston(row) for row in train_data])\n","\n","# -------------------------------------------------------------------------\n","# NAIVE MODEL\n","# -------------------------------------------------------------------------\n","# We take the last observed value [-1] and repeat it for the horizon H.\n","\n","# 1. Get the last value. Shape becomes (n_series, 1)\n","last_value = train_data[:, -1:]\n","\n","# 2. Tile it to match horizon. Shape becomes (n_series, 28)\n","naive_preds = np.tile(last_value, (1, H))\n","\n","# -------------------------------------------------------------------------\n","# GLOBAL MEAN MODEL\n","# -------------------------------------------------------------------------\n","# We calculate the mean over the time axis (axis 1).\n","\n","# 1. Calculate mean. keepdims=True ensures shape is (n_series, 1)\n","series_mean = np.mean(train_data, axis=1, keepdims=True)\n","\n","# 2. Tile it to match horizon. Shape becomes (n_series, 28)\n","mean_preds = np.tile(series_mean, (1, H))\n","\n","# -------------------------------------------------------------------------\n","# RW WITH DRIFT (Slope: First to Last)\n","# -------------------------------------------------------------------------\n","\n","# 1. Get the number of time steps (T) in the training history\n","n_timesteps = train_data.shape[1]\n","\n","# 2. Calculate the slope for each series\n","#    Slope = (Last Value - First Value) / (Total Time Steps - 1)\n","#    Note: We subtract 1 because there are T-1 intervals between T points.\n","y_last = train_data[:, -1:]\n","y_first = train_data[:, :1]\n","\n","# Shape (n_series, 1)\n","slope = (y_last - y_first) / (n_timesteps - 1)\n","\n","# 3. Create a horizon index vector [1, 2, ..., 28]\n","#    Shape (1, 28)\n","horizon_indices = np.arange(1, H + 1).reshape(1, H)\n","\n","# 4. Calculate Forecast\n","#    Pred = Last Value + (Slope * Horizon_Step)\n","#    Shape logic: (N, 1) + (N, 1) * (1, 28) -> (N, 28)\n","drift_preds = y_last + (slope * horizon_indices)\n","\n","# -------------------------------------------------------------------------\n","# 4. SAVE SUBMISSIONS & CALCULATE RMSE\n","# -------------------------------------------------------------------------\n","f_cols = [f\"F{i}\" for i in range(1, 29)]\n","\n","# Save SNAIVE yearly\n","sub_snaive = pd.DataFrame(snaive_preds, columns=f_cols)\n","sub_snaive.insert(0, 'id', ids)\n","sub_snaive.to_csv(\"submission_yearly_snaive.csv\", index=False)\n","\n","# Save SNAIVE weekly\n","sub_snaive = pd.DataFrame(snaive_weekly_preds, columns=f_cols)\n","sub_snaive.insert(0, 'id', ids)\n","sub_snaive.to_csv(\"submission_weekly_snaive.csv\", index=False)\n","\n","# Save SNAIVE\n","sub_snaive = pd.DataFrame(snaive_monthly_preds, columns=f_cols)\n","sub_snaive.insert(0, 'id', ids)\n","sub_snaive.to_csv(\"submission_monthly_snaive.csv\", index=False)\n","\n","# Save Croston\n","sub_croston = pd.DataFrame(croston_preds, columns=f_cols)\n","sub_croston.insert(0, 'id', ids)\n","sub_croston.to_csv(\"submission_croston.csv\", index=False)\n","\n","# Evaluation\n","# Align Ground Truth by ID\n","val_df_sorted = val_df.set_index('id').reindex(ids).reset_index()\n","y_true = val_df_sorted.drop(columns=['id']).values\n","\n","rmse_snaive = sqrt(mean_squared_error(y_true, snaive_preds))\n","rmse_snaive_w = sqrt(mean_squared_error(y_true, snaive_weekly_preds))\n","rmse_snaive_m = sqrt(mean_squared_error(y_true, snaive_monthly_preds))\n","rmse_naive = sqrt(mean_squared_error(y_true, naive_preds))\n","rmse_mean = sqrt(mean_squared_error(y_true, mean_preds))\n","rmse_drif = sqrt(mean_squared_error(y_true, drift_preds))\n","rmse_croston = sqrt(mean_squared_error(y_true, croston_preds))\n","\n","\n","print(\"Validation Set results:\")\n","print(f\"SNAIVE RMSE Yearly: {rmse_snaive:.4f}\")\n","print(f\"SNAIVE RMSE Weekly: {rmse_snaive_w:.4f}\")\n","print(f\"SNAIVE RMSE Monthly: {rmse_snaive_m:.4f}\")\n","print(f\"NAIVE RMSE: {rmse_naive:.4f}\")\n","print(f\"MEAN RMSE: {rmse_mean:.4f}\")\n","print(f\"DRIFT RMSE: {rmse_drif:.4f}\")\n","print(f\"Croston RMSE: {rmse_croston:.4f}\")"]}]}